{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilfetz22/gym-anytrading/blob/master/gym_anytrading/datasets/prepping_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS9OsB01zG39"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "import mplfinance\n",
        "from renkodf import Renko\n",
        "from scipy.signal import lfilter\n",
        "# import MetaTrader5 as mt5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQf0qbzszG4C"
      },
      "outputs": [],
      "source": [
        "filepath = \"C:/Users/WilliamFetzner/Documents/Trading/\"\n",
        "anytrading_filepath = \"/gym-anytrading/gym_anytrading/datasets/data/\"\n",
        "brick_size = 0.00081\n",
        "brick_size_str = str(int(brick_size*100000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8Lb24eHzG4D",
        "outputId": "9affecf4-5574-47f9-c85b-98c1405e6ab1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['EURUSD_11_15_22_to_11_14_23.csv',\n",
              " '3mo_EURUSD.csv',\n",
              " 'EURUSD_2_13_to_3_6.csv',\n",
              " 'EURUSD_3_6_to_3_8_24.csv',\n",
              " 'EURUSD_3_8_to_3_12_24.csv',\n",
              " 'EURUSD_3_12_to_3_22_24.csv',\n",
              " 'EURUSD_3_23_to_3_30_24.csv',\n",
              " 'EURUSD_11_15_17_to_11_15_18.csv',\n",
              " 'EURUSD_11_15_18_to_11_15_19.csv',\n",
              " 'EURUSD_11_15_19_to_11_15_20.csv',\n",
              " 'EURUSD_11_15_20_to_11_15_21.csv',\n",
              " 'EURUSD_11_15_21_to_11_15_22.csv']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # collect the actual data from csv file\n",
        "# # filename = \"C:/Users/WilliamFetzner/Documents/Trading/DAT_XLSX_EURUSD_M1_2023.xlsx\"\n",
        "\n",
        "# # exported from tickstory\n",
        "\n",
        "# yr_tickstory_csvs = []\n",
        "# for year in range(17, 22):\n",
        "#     yr_tickstory_csvs.append(f\"EURUSD_11_15_{year}_to_11_15_{year+1}.csv\")\n",
        "# tickstory_csvs = [\"EURUSD_11_15_22_to_11_14_23.csv\", \"3mo_EURUSD.csv\", \"EURUSD_2_13_to_3_6.csv\",\n",
        "#                     \"EURUSD_3_6_to_3_8_24.csv\", \"EURUSD_3_8_to_3_12_24.csv\", \"EURUSD_3_12_to_3_22_24.csv\",\n",
        "#                     \"EURUSD_3_23_to_3_30_24.csv\"]\n",
        "# tickstory_csvs.extend(yr_tickstory_csvs)\n",
        "# tickstory_csvs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNRI01l4zG4E"
      },
      "outputs": [],
      "source": [
        "csvs = [ 'EURUSD_11_15_17_to_11_15_18.csv',\n",
        " 'EURUSD_11_15_18_to_11_15_19.csv',\n",
        " 'EURUSD_11_15_19_to_11_15_20.csv',\n",
        " 'EURUSD_11_15_20_to_11_15_21.csv',\n",
        " 'EURUSD_11_15_21_to_11_15_22.csv',\n",
        " 'EURUSD_11_15_22_to_11_14_23.csv',\n",
        " '3mo_EURUSD.csv',\n",
        " 'EURUSD_2_13_to_3_6.csv',\n",
        " 'EURUSD_3_6_to_3_8_24.csv',\n",
        " 'EURUSD_3_8_to_3_12_24.csv',\n",
        " 'EURUSD_3_12_to_3_22_24.csv',\n",
        " 'EURUSD_3_23_to_3_30_24.csv',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dneczX-DzG4F"
      },
      "outputs": [],
      "source": [
        "# # df = pd.DataFrame()\n",
        "# for df_name in last_to_add:\n",
        "#     # check if filepath + \"EURUSD_11_15_17_to_3_30_24.csv\" exists\n",
        "#     if not os.path.exists(filepath + \"EURUSD_full_tickstory_data.csv\"):\n",
        "#         df = pd.DataFrame()\n",
        "#     else:\n",
        "#         df = pd.read_csv(filepath + \"EURUSD_full_tickstory_data.csv\")\n",
        "#     df_new = pd.read_csv(filepath + df_name)\n",
        "#     print(len(df_new), df_name)\n",
        "#     df = pd.concat([df, df_new], ignore_index=True)\n",
        "#     # save to csv\n",
        "#     df.to_csv(filepath + \"EURUSD_full_tickstory_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0f_KIYhzG4F"
      },
      "outputs": [],
      "source": [
        "def prep_data_fx(df):\n",
        "    df = df.reset_index(drop=True)\n",
        "    # drop any duplicate rows\n",
        "    df = df.drop_duplicates()\n",
        "    # convert date to datetime\n",
        "    df['datetime'] = pd.to_datetime(df['Timestamp'], format='%Y%m%d %H:%M:%S:%f')\n",
        "    # sort by datetime\n",
        "    df = df.sort_values(by='datetime')\n",
        "    # rename bid price to close\n",
        "    df.rename(columns={'Bid price':'close'}, inplace=True)\n",
        "    df_ready = df.set_index('datetime')\n",
        "    # adjust the datetime 7 hrs ahead to match market time\n",
        "    df_ready.index = df_ready.index + pd.Timedelta(hours=7)\n",
        "    # ohlc = df_ready[['close']]\n",
        "    return df_ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFnBUaM5zG4F"
      },
      "outputs": [],
      "source": [
        "def generate_renko(df, brick_size):\n",
        "    # create a renko chart from the ohlc_dec_1 dataframe\n",
        "    r_full = Renko(df, brick_size=brick_size)\n",
        "    # create a new dataframe from the renko features\n",
        "    renko_full_data = r_full.renko_df()\n",
        "    return renko_full_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mu8pKmbzctd"
      },
      "outputs": [],
      "source": [
        "for csv in csvs:\n",
        "    if os.path.isfile(f'{filepath}/prepped_{csv}'):\n",
        "        df = pd.read_csv(f'{filepath}/prepped_{csv}')\n",
        "        print(f'{csv} already prepped')\n",
        "    else:\n",
        "        df = pd.read_csv(filepath + csv)\n",
        "        df = prep_data_fx(df)\n",
        "        df.to_csv(f'{filepath}/prepped_{csv}', index=True)\n",
        "    # find the last day of the dataframe\n",
        "    last_day = df.index[-1].date()\n",
        "    # find the last 2 days of the dataframe by adding 1 day to the last day\n",
        "    last_2_days = last_day - pd.Timedelta(days=1)\n",
        "    # get the last 2 days of data\n",
        "    df_last_2_days = df.loc[df.index.date >= last_2_days]\n",
        "    # save it to a csv file\n",
        "    df_last_2_days.to_csv(f'{filepath}/prepped_last_2_days_{csv}', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-EmxSCkzG4G"
      },
      "outputs": [],
      "source": [
        "# make sure that none of the csvs have overlapping data\n",
        "for i, csv in enumerate(csvs):\n",
        "    df = pd.read_csv(f'{filepath}/prepped_last_2_days_{csv}')\n",
        "    if i == len(csvs) - 1:\n",
        "        print('we are at the end of the list, stop')\n",
        "        break\n",
        "    df2 = pd.read_csv(f'{filepath}/prepped_{csvs[i+1]}')\n",
        "    if df.index[-1] >= df2.index[0]:\n",
        "        # drop any rows in df2 that are in df by finding the intersection of the two indexes\n",
        "        df2 = df2.drop(df2.index.intersection(df.index), axis=0)\n",
        "    del df\n",
        "    # save it back to the csv without the overlap\n",
        "    df2.to_csv(f'{filepath}/prepped_{csvs[i+1]}', index=True)\n",
        "    del df2\n",
        "    print(f'finished {i} loop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw26yrwgzG4G"
      },
      "outputs": [],
      "source": [
        "for i, csv in enumerate(csvs):\n",
        "    df = pd.read_csv(f'{filepath}/prepped_{csv}')\n",
        "    # convert the 'datetime' column to datetime\n",
        "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "    # set the datetime column as the index\n",
        "    df = df.set_index('datetime')\n",
        "    df_prepped = df[['close']]\n",
        "    if i == 0:\n",
        "        renko_full_data = generate_renko(df_prepped, brick_size)\n",
        "        renko_full_data = renko_full_data.sort_values(by='datetime')\n",
        "        year = renko_df.index[0].year\n",
        "        year_end = renko_df.index[-1].year\n",
        "        # save renko_df to csv\n",
        "        renko_df.to_csv(f'{filepath}/renko_full_data_{brick_size_str}_{year}_{year_end}.csv')\n",
        "        # save renko_full_data to csv\n",
        "        renko_full_data.to_csv(f'{filepath}/renko_full_data_{brick_size_str}.csv', index=True)\n",
        "    else:\n",
        "        # find the first value of in the df_prepped that is greater than or equal to the absolute value of the  difference between last_row.close and df_prepped.close\n",
        "        # first create a new column in df_prepped that is the absolute value of the difference between the close and last_row.close\n",
        "        df_prepped['diff'] = np.where(abs(df_prepped['close'] - last_row['close'].values[0]) >= brick_size, 1, 0)\n",
        "        # find the first index where diff is 1\n",
        "        first_index = df_prepped[df_prepped['diff'] == 1].index[0]\n",
        "        # get the dataframe from first_index to the end\n",
        "        df_prepped_adjusted = df_prepped.loc[first_index:]\n",
        "        # generate the renko chart\n",
        "        renko_df = generate_renko(df_prepped, brick_size)\n",
        "        year = renko_df.index[0].year\n",
        "        year_end = renko_df.index[-1].year\n",
        "        # save renko_df to csv\n",
        "        renko_df.to_csv(f'{filepath}/renko_full_data_{brick_size_str}_{year}_{year_end}.csv')\n",
        "        # concatenate the renko_df to the renko_full_data.csv\n",
        "        renko_full_data = pd.read_csv(f'{filepath}/renko_full_data_{brick_size_str}.csv')\n",
        "        # convert the 'datetime' column to datetime\n",
        "        renko_full_data['datetime'] = pd.to_datetime(renko_full_data['datetime'])\n",
        "        # reset the index of renko_df\n",
        "        renko_df = renko_df.reset_index()\n",
        "        renko_full_data = pd.concat([renko_full_data, renko_df], ignore_index=True)\n",
        "        # sort by datetime\n",
        "        renko_full_data = renko_full_data.sort_values(by='datetime')\n",
        "        # save to csv\n",
        "        renko_full_data.to_csv(f'{filepath}/renko_full_data_{brick_size_str}.csv', index=False)\n",
        "    renko_datetime_close = renko_full_data.loc[:, ['datetime', 'close']]\n",
        "    # get the last row of the renko full data\n",
        "    last_row = pd.DataFrame(renko_datetime_close.iloc[-1]).T\n",
        "    del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OLGoWIPzG4H"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(filepath + \"EURUSD_full_tickstory_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBg9eY7tzG4H"
      },
      "outputs": [],
      "source": [
        "# df19_20 = pd.read_csv(filepath + \"EURUSD_11_15_19_to_11_15_20.csv\")\n",
        "# df20_21 = pd.read_csv(filepath + \"EURUSD_11_15_20_to_11_15_21.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMcRbyRxzG4H",
        "outputId": "5f35d4c9-8857-4b6e-d1f8-78eeecc0b57c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Bid price</th>\n",
              "      <th>Ask price</th>\n",
              "      <th>Bid volume</th>\n",
              "      <th>Ask volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Timestamp, Bid price, Ask price, Bid volume, Ask volume]\n",
              "Index: []"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # find out if there are any missing data from df20_21 that is not in df\n",
        "# missing_data = df20_21.loc[~df20_21['Timestamp'].isin(df['Timestamp'])]\n",
        "# missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTaRj59ozG4I"
      },
      "outputs": [],
      "source": [
        "# df = prep_data_fx(df)\n",
        "# df.to_csv(filepath + \"EURUSD_full_tickstory_data_prepped.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrE6ToXKzG4I"
      },
      "outputs": [],
      "source": [
        "# renko_full_data = generate_renko(df, 0.00081, ending='_initial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtyF-d3mzG4I",
        "outputId": "80cfc0ba-6fc3-49cc-da1e-1b0ffc23a42f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-11-15 09:01:29.782</td>\n",
              "      <td>1.17936</td>\n",
              "      <td>1.18017</td>\n",
              "      <td>1.17846</td>\n",
              "      <td>1.18017</td>\n",
              "      <td>12545.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-11-15 09:09:28.118</td>\n",
              "      <td>1.18017</td>\n",
              "      <td>1.18098</td>\n",
              "      <td>1.17990</td>\n",
              "      <td>1.18098</td>\n",
              "      <td>775.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-11-15 10:01:52.936</td>\n",
              "      <td>1.18098</td>\n",
              "      <td>1.18179</td>\n",
              "      <td>1.18035</td>\n",
              "      <td>1.18179</td>\n",
              "      <td>4685.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-11-15 10:08:27.340</td>\n",
              "      <td>1.18179</td>\n",
              "      <td>1.18260</td>\n",
              "      <td>1.18162</td>\n",
              "      <td>1.18260</td>\n",
              "      <td>793.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-11-15 10:50:31.737</td>\n",
              "      <td>1.18260</td>\n",
              "      <td>1.18341</td>\n",
              "      <td>1.18121</td>\n",
              "      <td>1.18341</td>\n",
              "      <td>3910.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  datetime     open     high      low    close   volume\n",
              "0  2017-11-15 09:01:29.782  1.17936  1.18017  1.17846  1.18017  12545.0\n",
              "1  2017-11-15 09:09:28.118  1.18017  1.18098  1.17990  1.18098    775.0\n",
              "2  2017-11-15 10:01:52.936  1.18098  1.18179  1.18035  1.18179   4685.0\n",
              "3  2017-11-15 10:08:27.340  1.18179  1.18260  1.18162  1.18260    793.0\n",
              "4  2017-11-15 10:50:31.737  1.18260  1.18341  1.18121  1.18341   3910.0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# renko_full_data = pd.read_csv(f\"{filepath}{anytrading_filepath}renko_full_data_81_initial.csv\")\n",
        "# renko_full_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZfBFxjQzG4I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
